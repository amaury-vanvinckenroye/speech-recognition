{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender classification\n",
    "\n",
    "#### Description\n",
    "\n",
    "This is a simple gender classification based on the mean pitch level of the frames.\n",
    "\n",
    "A model is trained by using an optimization function on the mean pitch level.\n",
    "\n",
    "#### Methods\n",
    "\n",
    "Librosa (Pyin), optimzation function, model classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import librosa \n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read train csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "\n",
    "df_train = pd.read_csv(data_dir / \"cv-valid-train.csv\")\n",
    "print(len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display examples of speeches\n",
    "Plot one female frame and one male frame. \n",
    "\n",
    "We estimate the pitch using the Yin and Pyin algorithms, and compare the results. The pitch estimations are plotted onto the spectrogram. The flags drawn on the audio signal originate from the Pyin algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = df_train[~df_train.gender.isna()]\n",
    "print(len(df_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_female = df_gender[df_gender.gender == \"female\"].iloc[0]\n",
    "row_male = df_gender[df_gender.gender == \"male\"].iloc[0]\n",
    "\n",
    "for row in [row_female, row_male]:\n",
    "    audio_file = data_dir / row.filename\n",
    "\n",
    "    signal, sr = librosa.load(str(audio_file.resolve()), sr=None)\n",
    "\n",
    "    ## Yin algorithm\n",
    "    # use the recommended C2 (~65 Hz) and C7 (~2093 Hz) for fmin and fmax\n",
    "    # default frame length is 2048 for sr=22050\n",
    "    frame_length = 4096\n",
    "    f0_yin = librosa.yin(signal, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr, frame_length=frame_length)\n",
    "    times_f0_yin = librosa.times_like(f0_yin, sr=sr, hop_length=frame_length//4)\n",
    "\n",
    "    ## Pyin algorithm\n",
    "    # Gives the advantage to return a flag indicating the frame is voiced or not\n",
    "    frame_length = 4096\n",
    "    f0_pyin, voiced_flag, voiced_probs = librosa.pyin(signal, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr, frame_length=frame_length)\n",
    "    times_f0_pyin = librosa.times_like(f0_pyin, sr=sr, hop_length=frame_length//4)\n",
    "\n",
    "\n",
    "    ## Spectrogram\n",
    "    spec = librosa.amplitude_to_db(np.abs(librosa.stft(signal, n_fft=1024, hop_length=512)), ref=np.max)\n",
    "\n",
    "    ## Plot\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(13, 7), sharex=True)\n",
    "    fig.suptitle(f\"{row.filename} - {row.gender}\")\n",
    "    librosa.display.waveshow(signal, sr=sr, x_axis=\"time\", ax=ax[0])\n",
    "    axright = ax[0].twinx()\n",
    "    axright.plot(times_f0_pyin, voiced_flag, color=\"C1\")\n",
    "    axright.plot(times_f0_pyin, voiced_probs, color=\"C2\", linestyle=\":\")\n",
    "    librosa.display.specshow(spec,sr=sr, hop_length=512, x_axis='time', y_axis='log', ax=ax[1])\n",
    "    ax[1].plot(times_f0_yin, f0_yin, label='f0', color='cyan', linewidth=3)\n",
    "    ax[1].plot(times_f0_yin, [200] * len(times_f0_yin), color=\"k\", linestyle=\"--\")\n",
    "    ax[1].set_title(\"Yin algorithm\")\n",
    "    librosa.display.specshow(spec,sr=sr, hop_length=512, x_axis='time', y_axis='log', ax=ax[2])\n",
    "    ax[2].plot(times_f0_pyin, f0_pyin, label='f0', color='cyan', linewidth=3)\n",
    "    ax[2].plot(times_f0_pyin, [200] * len(times_f0_pyin), color=\"k\", linestyle=\"--\")\n",
    "    ax[2].set_title(\"Pyin algorithm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Build the inputs for a ML model. The mean pitch is calculated using the Pyin algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "gender_map = {\n",
    "    \"female\": 0,\n",
    "    \"male\": 1\n",
    "}\n",
    "\n",
    "def load_audio(filename):\n",
    "    audio_file = data_dir / filename\n",
    "    # ignore known warning caused by PySoundFile not able to read .mp3 files\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        signal, sr = librosa.load(str(audio_file.resolve()), sr=None)\n",
    "    return signal, sr\n",
    "\n",
    "def apply_pyin(signal, sr):    \n",
    "    ## Pyin algorithm\n",
    "    # used over the Yin algorithm because it gives the advantage to return a flag indicating the frame is voiced or not\n",
    "    # use the recommended C2 (~65 Hz) and C7 (~2093 Hz) for fmin and fmax\n",
    "    # default frame length is 2048 for sr=22050\n",
    "    frame_length = 2048 * (sr//22050)\n",
    "    f0, voiced_flag, voiced_probs = librosa.pyin(signal, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr, frame_length=frame_length)\n",
    "    return f0, voiced_flag, voiced_probs\n",
    "\n",
    "def process_audio(df_row):\n",
    "    signal, sr = load_audio(df_row.filename)\n",
    "    f0, _, _ = apply_pyin(signal, sr)  # voiced_flags and voiced_probs are unused here\n",
    "    if not np.all(np.isnan(f0)): \n",
    "        return np.nanmean(f0), gender_map[df_row.gender]\n",
    "    else:\n",
    "        # return the filename in case no voice was detected\n",
    "        return None, df_row.filename\n",
    "\n",
    "\n",
    "#### Build feature set \n",
    "run_parallel = False\n",
    "size_include = 100\n",
    "\n",
    "x, y = [], []\n",
    "silent_frames = []\n",
    "\n",
    "if run_parallel:\n",
    "    processed = Parallel(n_jobs=-1)(delayed(process_audio)(row) for row in df_gender.iloc[:size_include].itertuples())\n",
    "    for mean_pitch, gender in processed:\n",
    "        # only include voiced frames\n",
    "        if mean_pitch is not None:\n",
    "            x.append(mean_pitch)\n",
    "            y.append(gender)\n",
    "        else:\n",
    "            silent_frames.append(gender)\n",
    "\n",
    "else:\n",
    "    for row in df_gender.iloc[:size_include].itertuples():\n",
    "        mean_pitch, gender = process_audio(row)\n",
    "        # only include voiced frames\n",
    "        if mean_pitch is not None:\n",
    "            x.append(mean_pitch)\n",
    "            y.append(gender)\n",
    "        else:\n",
    "            silent_frames.append(gender)\n",
    "\n",
    "print(f\"Size of data: {len(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature inspection\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n",
    "\n",
    "xfemale = X_train[np.where(y_train == 0)[0]]\n",
    "xmale = X_train[np.where(y_train == 1)[0]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "ax.hist(xfemale, alpha=0.4, label=\"female\")\n",
    "ax.hist(xmale, alpha=0.4, label=\"male\")\n",
    "ax.set_xlabel(\"Mean F0 (pitch) [Hz]\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "Use an optimization function to derive the pitch level that best discrimates gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "class GenderClassifier:\n",
    "    def __init__(self, pitch_thresh_estim):\n",
    "        self.pitch_thresh_estim = pitch_thresh_estim        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        res = minimize(self.loss, [self.pitch_thresh_estim], args=(X, y), method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
    "        if res.success:\n",
    "            self.pitch_thresh_optim = res.x[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Could not train - {res.message}\")\n",
    "\n",
    "    def predict(self, X, pitch_thresh=None):\n",
    "        X = np.array(X)\n",
    "        y = np.zeros(len(X))\n",
    "        if pitch_thresh is None:\n",
    "            pitch_thresh = self.pitch_thresh_optim\n",
    "        y[np.where(X < pitch_thresh)[0]] = 1    \n",
    "        return y       \n",
    "\n",
    "    def loss(self, pitch_thresh, X, y):\n",
    "        # returns the amount of mistakes\n",
    "        pitch_thresh = np.atleast_1d(pitch_thresh)\n",
    "        ypred = self.predict(X, pitch_thresh=pitch_thresh[0])  \n",
    "        return np.sum(y != ypred)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        # returns the accuracy\n",
    "        return 1 - self.loss(self.pitch_thresh_optim, X, y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GenderClassifier(200)  # rough estimation of pitch threshold is 200 Hz\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(f\"Score on test set: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "ax.hist(xfemale, alpha=0.4, label=\"female\")\n",
    "ax.hist(xmale, alpha=0.4, label=\"male\")\n",
    "ylims = ax.get_ylim()\n",
    "ax.vlines(clf.pitch_thresh_optim, ylims[0], ylims[1], color=\"r\", linestyle=\"--\")\n",
    "ax.set_ylim(ylims)\n",
    "ax.set_xlabel(\"Mean F0 (pitch) [Hz]\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_title(f\"Optimal threshold for F0: {clf.pitch_thresh_optim} Hz\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ae9b6b132d771837cdcfd7bbb0ca696bfddd0e5ccecb2afe4839e903db6d0ff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
